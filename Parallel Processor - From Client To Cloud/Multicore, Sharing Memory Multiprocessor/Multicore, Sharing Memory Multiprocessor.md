-----
### 멀티 코어와 기타 공유 메모리 프로세서
-----
1. 하드웨어 멀티스레딩 추가 비용을 크게 들이지 않고, 프로세서의 효율을 높이기는 했지만, 칩에 집적되는 프로세서 수가 많아지면서 많은 프로세서를 효율적으로 성능 개선하는 것이 큰 문제가 됨
2. 한 가지 답은 모든 프로세서들이 공유하는 단일 실제 주소 공간을 제공하는 것 : 프로그램들은 자신들이 사용할 데이터가 어디에 있는지 신경 쓸 필요가 없이 병렬적으로 수행될 수 있음
   - 이 방식에서는 언제나 또 어느 프로세서나 프로그램의 모든 변수에 접근할 수 있음
3. 다른 방식은 프로세서마다 별도의 주소 공간을 갖고 공유할 것이 있으면 명시적으로 표시하는 것
   - 실제 주소 공간이 공유될 때는 하드웨어가 캐시 일관성을 보장하여 모든 프로세서가 공유 메모리에 대해 일치된 관점(Consistent View)를 가지도록 하는 것이 일반적
4. 공유 메모리 멀티프로세서(Shared Memory Multiprocessor, SMP)에서는 모든 프로세서가 단일 실제 주소 공간을 가지며 멀티코어 칩은 거의 다 이런 방식으로 구현
   - 프로세서들은 어느 메모리 주소든지 저갲와 저장 명령어를 사용하여 접근할 수 있으며, 프로세서 간 통신은 메모리에 있는 공유 변수를 통해 이루어짐
   - SMP의 전형적인 구조 : 프로세서들이 실제 주소 공간을 공유하더라도 작업들은 각각 별개의 가상 주소 공간에서 독립적으로 수행될 수 있음
<div align="center">
<img src="https://github.com/user-attachments/assets/cee5f7bf-9fdc-4fcd-bf4e-0406958097d1">
</div>

5. 단일 주소 공간 멀티프로세서에는 두 가지 스타일이 존재
   - 한 가지는 어느 프로세서가 어느 워드에 접근하든지 간에 동일한 시간이 걸리는 스타일 : 균일 메모리 접근(Uniform Memory Access, UMA) 멀티프로세서라고 함
     + 어떤 프로세서가 메모리에 있는 어떤 워드를 접근하든지 균일한 시간이 걸리는 멀티프로세서
   - 두 번째 스타일은 어떤 프로세서가 어떤 워드를 접근하는지 따라 메모리 접근 시간이 달라짐 : 이러한 기계를 비균일 메모리 접근(Non-uniform Memory Aceess, NIUMA) 멀티프로세서라고 함
     + 즉, 메인 메모리가 여러 조각으로 분할되어서 각각이 다른 마이크로프로세서 또는 동일 칩 내의 다른 메모리 제어기에 붙어 있음
     + 단일 주소 공간 멀티프로세서의 일종으로 어떤 워드를 접근하는지에 따라 일부 메모리 접근이 다른 경우보다 훨씬 빠른 멀티프로세서
   - NUMA 멀티프로세서가 UMA 멀티프로세서보다 프로그래밍하기 어렵지만, NUMA 멀티프로세서는 가까운 메모리를 빨리 접근할 수 있고 규모를 크게 만들 수 있음

6. 동시에 동작하는 프로세서들끼리 데이터를 공유하는 것이 일반적이므로 공유 데이터에 대한 작업을 할 때는 조정이 필요
   - 조정이 이루어지지 않으면 한 프로세서가 공유 데이터에 대한 작업을 끝내기도 전에 다른 프로세서가 같은 데이터에 대한 작업을 시작할 수 있는데, 이 조정 작업을 동기화(Synchronization, 둘 이상 프로세서들의 동작을 조정하는 작업으로, 이 프로세스들은 서로 다른 프로세서에서 실행되고 있을 수 있음)
   - 단일 주소 공간에서 공유가 허용되는 경우에는 동기화를 위한 별도 메커니즘이 필요한데, 한 가지 방법은 공유 변수에 대한 잠금변수(Lock, 한 번에 한 프로세서에서만 데이터를 접근할 수 있게 하는 동기화 장치)을 이용하는 것
     + 한 번에 한 프로세서만 잠금 변수를 얻을 수 있고, 공유변수를 사용하고자 하는 다른 프로세서들은 그 프로세서가 잠금을 풀 때까지 기다려야 함

7. 예) 공유 주소 공간에서의 단순한 병렬 처리 프로그램 : UMA 구조의 공유 메모리 멀티프로세서 컴퓨터에서 64,000개 숫자를 더하는 프로그램 작성 (프로세서 수는 64개라고 가정)
   - 첫 번째 단계는 숫자들을 동일한 크기의 묶으으로 나누어서 프로세서 간의 부하를 균등하게 만드는 것
     + 이 컴퓨터는 단일 주소 공간을 갖고 있으므로 나눈 묶음들을 다른 메모리 공간에 할당할 필요는 없음
     + 각 프로세서마다 서로 다른 시작 주소를 지정해주기만 하면 됨
     + Pn이 0부터 63까지의 프로세서 번호라고 가정하고, 모든 프로세서는 자기에게 할당된 숫자들을 더하는 순환문으로 프로그램 수행 시작
<div align="center">
<img src="https://github.com/user-attachments/assets/881a32a9-ab08-4328-884a-4833f7879b63">
</div>

   - 그 다음 단계는 64개의 부분합들을 더하는 것으로, 이 단계를 리덕션(Reduction, 자료구조에 연산을 수행하여 한 숫자로 결과를 얻는 함수)이라고 하며, 여기서는 분할 정복(Divide-and-Conquer) 방법을 사용
     + 프로세서들의 절반이 부분합 2개씩을 더하고, 다시 프로세서의 1/4이 새롭게 얻은 부분합 2개씩을 더함
     + 합이 하나가 될 때까지 이 과정을 반복
     + 리덕션 과정
<div align="center">
<img src="https://github.com/user-attachments/assets/c78df49b-9109-481f-b213-097877695811">
</div>

   - 이 예제에서 생산자 프로세서가 메모리 위치에 값을 쓴 이후 소비자 프로세서가 그 값을 읽어가도록 두 프로세서 간에 동기화가 이루어져야 함
   - 그렇지 않으면 소비자 데이터가 이전 값을 읽을 수 있으며, 그리고 각 프로세서는 반복 제어 변수 i를 자신만 사용하도록 사적 변수(Private Variable)로 지정해야 함
   - 프로그램 코드 (half도 사적 변수)
<div align="center">
<img src="https://github.com/user-attachments/assets/62d1ac2c-5821-4cdb-bb96-59aa84e6c67a">
</div>

8. OpenMP : UNIX나 마이크로소프트 플랫폼에서 수행되는 공유 메모리 멀티 프로세싱을 위한 API로 C, C++, Fortran을 지원하며, 여기에는 컴파일러 지시어와 라이브러리, 런타임 지시어가 포함
   - 이것은 컴파일러 지시어, 환경 변수 그리고 표준 프로그래밍 언어를 확장할 수 있는 런타임 라이브러리 루틴이 붙은 API(Application Programmer Interface)
     + OpenMP는 공유 메모리 멀티프로세서를 위한 이식성이 있고, 확장성 있는 단순한 프로그래밍 모델을 제공
     + 주된 목적은 순환문을 병렬화하고 리덕션을 수행하는 것
   - 대부분의 C 컴파일러는 이미 OpenMP를 지원하고 있음 : UNIX C에서 OpenMP API를 사용하기 위한 명령어
```
cc -fopenmp foo.c
```
   - OpenMP는 pragma를 이용해 C언어를 확장하는데, 이는 #define이나 $include처럼 C 매크로 전처러기를 위한 명령어
   - 위 예제와 같이 프로세스 개수를 64개로 정해주려면 다음 명령 사용
<div align="center">
<img src="https://github.com/user-attachments/assets/d576030a-46e3-482d-bfd3-8549f7dbe1e7">
</div>

   - 런타임 라이브러리가 64개의 병렬 스레드를 사용할 것이라는 뜻
   - 순차적은 for 순환문을 병렬 for 순환문으로 바꾸기 위해 지정한 개수의 스레드 수만큼 작업을 나누어야 함 (sum은 0으로 초기화되었다고 가정)
<div align="center">
<img src="https://github.com/user-attachments/assets/18f23bdd-d9d1-4d11-8231-7706963c878f">
</div>

   - 리덕션을 수행하기 위해 리덕션 연산의 종류와 리덕션 결과를 넣을 변수를 OpenMP에게 알려주는 명령을 사용할 수 있음
<div align="center">
<img src="https://github.com/user-attachments/assets/c1598ff9-33d0-402f-958a-49852ccb904b">
</div>

   - OpenMP가 간단한 병렬 코드 작성을 쉽게 해주기는 하지만, 디버깅에는 큰 도움을 주지 못하므로, 이보다 더 정교한 병렬 프로그래밍 시스템을 사용하는 병렬 프로그래머들이 많아지고 있음

9. SMP를 대칭적 멀티프로세서(Symmetric Multiprocessor)의 약어라고 하는 경우도 많은데, 그 의미는 모든 프로세서로부터 메모리까지 지연시간이 거의 같다는 것
    - 이렇게 하는 이유는 SMP처럼 단일 주소 공간을 사용하는 대규모 NUMA 멀티프로세서와 구별하기 위함
    - 하지만 대규모 NUMA 멀티프로세서보다 클러스터가 훨씬 많이 사용되고 있으므로, 원래 뜻대로 사용해서 클러스터처럼 여러 개 주소 공간을 사용하는 것들과 대비하고자 함

10. 실제 주소 공간을 공유하는 대신 각각 별도 실제 주소 공간을 갖되 가상 주소 공간을 공유하게 할 수 있음
    - 이 때, 통신 문제는 운영체제가 담당하게 되지만, 실제 이런 방법은 오버헤드가 너무 커서 좋은 성능을 원하는 프로그래메에게 공유 메모리처럼 보이게 하는 것은 어려움
