-----
### 캐시 접근
-----
1. 비어 있는 블록 8개로 구성된 캐시가 있을 때, 아홉 번의 메모리 참조
<div align="center">
<img src="https://github.com/user-attachments/assets/68011b74-71f3-401a-a6d8-0cc700b73135">
</div>

   - 캐시 실패가 발생할 때마다 캐시 내용이 어떻게 변화되는지 보여주는 그림
<div align="center">
<img src="https://github.com/user-attachments/assets/057db6af-5a03-4184-9ad7-6da8431a12c5">
</div>

   - 캐시 내 8개 블록이 있으므로 주소의 하위 3비트가 블록 번호
   - 캐시가 비어있으므로 처음 몇 개 참조는 실패가 됨
   - 여덟 번쨰 참조에서 블록에 대한 충돌이 발생
     + 주소 18($10010_{2}$)의 워드가 캐시 블록 2($010_{2}$)에 들어가야 함
     + 따라서, 이미 캐시 블록 2($010_{2}$)에 있는 주소 26($11010_{2}$)의 워드는 교체되어야 함
     + 이러한 동작은 최근에 참조된 워드가 더 이전에 참조된 워드를 대체하여 캐시가 시간적 지역성을 활용할 수 있게 함

2. 메모리 주소가 주어지면 캐시의 어느 곳을 찾아봐야 하는지 바로 알 수 있음
   - 주소의 하위 비트들을 사용해서 이 주소가 사상되는 유일한 캐시 엔트리를 찾을 수 있음
<div align="center">
<img src="https://github.com/user-attachments/assets/fcee7a25-9fe8-43c6-9da0-44af8dc3b4b0">
</div>

  - 캐시의 태그 필드 값과 비교하는 데 사용하는 태그 필드
  - 블록을 선택하는 데 사용하는 캐시 인덱스

  - 캐시 블록의 인덱스와 그 블록의 태그 값이 캐시 블록에 있는 워드의 메모리 주소를 표시
  - 인덱스 필드가 캐시를 접근하는 주소로 이용
  - n비트 필드는 $2^{n}$개의 값을 가지므로, 직접 사상 캐시 전체 엔트리 수는 2의 거듭제곱이 되어야 함
  - MIPS 구조에는 정렬 제약이 있어서 모든 워드 주소가 4의 배수이므로, 주소의 최하위 2비트는 워드 내 바이트 순서를 나타냄
    + 따라서, 주소의 최하위 두 비트는 블록 내 워드를 선택할 때 사용되지 않음

3. 캐시는 데이터뿐만 아니라 태그도 저장해야하므로 캐시 구현에 필요한 총 비트 수는 캐시 크기와 주소 크기에 따라 결정
   - 32비트 주소
   - 직접 사상 캐시
   - 캐시에 $2^{n}$ 블록이 있어서 n비트가 인덱스로 사용
   - 캐시 블록의 크기는 $2^{m}$워드($2^{m + 2}$ 바이트)
     + 따라서, 주소의 m비트는 블록 내 워드를 구별하는 데 쓰이며, 2비트는 워드 내 바이트를 구별하는 역할을 하지만 캐시 접근할 때 사용하지 않음

   - 태그 필드의 크기 : 32 - (n + m + 2)
   - 직접 사상 캐시의 전체 비트 수 : $2^{n}$ X (블록 크기 + 태그 크기 + 유효 비트 크기)
   - 블록의 크기는 $2^{m}$ 워드 ($2^{m + 5}$ 비트)이고, 유효 필드를 위해 1비트가 필요하므로 캐시 전체 비트 수는
<div align="center">
<img src="https://github.com/user-attachments/assets/820429ed-5154-497c-b28e-f0134347bf3d">
</div>

   - 하지만 일반적으로 캐시 크기라고 말할 때는 유효 비트와 태그 필드 크기는 제외하고 데이터 크기만 따짐
   - 따라서 캐시에는 4 KiB의 데이터뿐만 아니라 2.625 KiB 크기의 태그와 유효 비트도 있지만, 4 KiB 캐시라고 부름

4. 예) 캐시의 전체 비트 수
   - 16 KiB의 데이터와 4워드 블록을 갖는 직접 사상 캐시의 구현에 필요한 전체 비트 수 (단, 32비트 주소를 가정)
   - 16 KiB는 4096($2^{12}$ = 16384 / 4)워드이며, 한 블록이 4($2^{2}$)워드이므로 이 캐시에는 1024($2^{10}$)개의 블록이 존재
   - 각 블록에는 4 X 32 = 128비트 데이터와 (32 - 10 - 2 - 2) = 18비트 태그, 그리고 한 비트의 유효 비트가 존재
   - 전체 캐시의 크기
<div align="center">
<img src="https://github.com/user-attachments/assets/ad51abc0-1d30-44b7-99fd-8103b837267d">
</div>

   - 즉, 16 KiB 캐시를 구현하려면 18.4 KiB 메모리가 필요 : 그러므로 이 캐시에서 전체 비트 수는 데이터 저장에 필요한 공간보다 약 1.15배 큼

5. 여러 워드 블록을 갖는 캐시의 주소 사상
   - 블록 크기가 16바이트, 블록 개수가 64개인 캐시에서 바이트 주소 1200은 몇 번 블록으로 사상되는가?
   - 블록 번호 : (블록 주소) modulo (캐시 내 블록 수)
   - 블록 주소 : 바이트 주소 / 블록 당 바이트 수
<div align="center">
<img src="https://github.com/user-attachments/assets/0d91dcbb-b3a0-4a79-a511-2b1f7593c153">
</div>

   - 블록당 바이트 수가 16이므로, 바이트 주소 1200의 블록 주소
<div align="center">
<img src="https://github.com/user-attachments/assets/2a186043-1495-4fa5-8118-0502c70bceb1">
</div>

   - 이는 캐시 블록 번호 (75 modulo 64) = 11에 사상
   - 이 블록에는 1200번지와 1215번지 사이의 모든 주소가 사상

6. 블록이 크면 공간적 지역성을 더 잘 활용해서 실패율이 낮아짐
<div align="center">
<img src="https://github.com/user-attachments/assets/37180a48-90d3-4709-ad66-09cdba542aa5">
</div>

   - 블록 크기를 늘리면 대개 실패율은 줄어듬
   - 하지만 블록이 너무 커서 블록 하나가 캐시의 상당 부분을 차지하게 되면 실패율이 오히려 커질 수 있음 : 캐시 내 블록 개수가 너무 적어서 블록에 대한 경쟁이 심해지기 때문임
   - 결과적으로 블록 내 워드를 별로 사용하지 못했는데, 그 블록이 캐시에서 쫓겨나게 됨 : 즉, 블록 크기가 매우 클 경우 블록 내 워드 간의 공간적 지역성이 감소하게 되어 실패율의 이득이 줄어듬

7. 블록 크기 증가와 연관되는 더 심각한 문제는 실패 비용이 증가하는 것
   - 실패 손실은 메모리 계층구조의 다음 하위 계층에서 블록을 가져와서 캐시에 적재하는 데 걸리는 시간에 의해 결정
   - 블록을 가져오는 데 걸리는 시간은 두 부분으로 구성
     + 첫 번째 워드를 가져오는 데 걸리는 접근 지연(Latency)과 블록의 나머지 부분에 대한 전송시간 : 메모리 시스템이 바뀌지 않는 한 블록 크기가 늘어나면 날수록 전송시간(따라서, 실패 소실)이 증가할 것
     + 게다가 실패율의 향상도 블록의 크기가 증가함에 따라 감소하기 시작함
     + 결과적으로 블록이 너무 커지면 실패 손실의 증가가 실패율 감소를 압도하게 되고 캐시의 성능 또한 감소하게 됨
     + 물론 큰 블록을 보다 효율적으로 전송할 수 있게 메모리를 설계한다면 블록의 크기를 크게 할 수 있고 캐시의 성능 또한 더 개선할 수 있음

8. 큰 블록의 실패 손실 중 지연시간 부분에 대해서 어떤 조치를 취하기 힘들다 하더라도, 전송시간은 일부를 보이지 않게 해서 실패 손실을 효과적으로 줄일 수 있음
   - 이렇게 하는 가장 간단한 방법은 조기 재시작(Early Restart) 방식으로, 블록 전체를 기다리지 않고 블록 내 요청된 워드가 도달하면 곧바로 실행을 시작하는 것
     + 많은 시스템들이 명령어 접근에 이 기법을 이용하고 있으며 효과가 좋음
     + 명령어 접근은 대개가 순차적이므로, 메모리 시스템이 매 클럭 사이클마다 한 워드 씩 보낼 수 있다면, 프로세서는 요구한 명령어를 바로 받아서 실행을 시작할 수 있음
     + 이 방법은 데이터 캐시에는 덜 효과적 : 블록 내 워드 요청이 예측하기 어려운 방식으로 이루어지는 경향이 있고, 데이터 전송이 다 끝나기도 전 다른 캐시 블록의 워드를 필요로 할 가능성이 높기 때문임
     + 전송이 진행 중이라 프로세서가 데이터 캐시에 접근할 수 없으면 프로세스는 지연될 수 밖에 없음

   - 좀 더 정교한 기법은 요청한 워드가 메모리에서 캐시로 제일 먼저 전송되도록 메모리를 구성하는 것
     + 그 다음에는 요청된 워드의 다음 주소부터 순서대로 전송하고, 블록 끝까지 전송한 후에는 다시 블록의 처음 워드부터 남은 워드들을 순차적으로 전송
     + 이 기법은 요구 워드 우선(Requested Word First) 방식 또는 중요 워드 우선(Critical Word First) 방식이라 불리며, 조기 재시작  방식보다는 조금 빠르지만 여전히 조기 재시작 방식과 마찬가지 한계를 가짐
