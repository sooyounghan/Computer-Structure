-----
### 블로킹을 이용한 소프트웨어 최적화
-----
1. 성능 향상에 메모리 계층 구조가 중요하므로 극적인 성능 향상을 이룰 수 있는 소프트웨어 최적화 방법이 많이 제시
   - 이 방법들은 캐시 내 데이터를 재사용하여 시간적 지역성을 개선함으로써 실패율을 낮춤

2. 배열을 다룰 때 배열에 대한 접근이 메모리에서 순차적으로 이루어질 수 있도록 메모리에 저장할 때 좋은 성능을 얻을 수 있음
   - 어떤 배열들은 행으로 접근되고, 어떤 배열들은 열로 접근되는 경우를 가정
     + 배열을 행 단위(행 우선 순서)로 저장하거나 열 단위(열 우선 순서)로 저장한다고 해서 문제가 해결되지 않음 : 순환문을 반복할 때마다 행도 사용되고 열도 사용되기 떄문임

   - 블록화 알고리즘은 배열의 행과 열 전체를 처리하는 대신 부분행렬(Submatrix) 또는 블록 단위로 처리
     + 캐시에 적재된 데이터가 교체되기 전에 최대한 사용하는 것이 목표로, 즉, 캐시 실패를 줄이기 위해 시간적 지역성을 향상시키는 것
     + 예) DGEMM의 내부 순환문
<div align="center">
<img src="https://github.com/user-attachments/assets/e6d10276-6b63-4bf8-8e4a-4ab922ccb4df">
</div>

   - B의 N X N 원소를 모두 읽고, A의 한 행에 해당하는 원소 N개를 반복적으로 읽고, C의 한 행에 해당하는 원소 N개를 씀 (주석은 행렬의 행과 열을 쉽게 파악할 수 있도록 해줌)
   - 세 배열에 대한 접근
<div align="center">
<img src="https://github.com/user-attachments/assets/0ee75900-4565-4c7b-88ff-442a4d0bc395">
</div>

   - 짙은 음영은 최근에 접근한 것들, 밝은 음영은 더 오래 전에 접근한 것들, 흰색은 아직 접근하지 않은 것을 보여줌
   - 용량 실패의 횟수가 N과 캐시 크기에 따라 달라지며, 캐시 충돌이 없을 때 N X N 행렬 3개를 다 저장할 수 있으면 좋음
   - 캐시가 N X N 행렬과 N 원소 행 하나를 저장할 수 있으면, 최소한 A의 i 번째 행과 배열 B는 캐시에 들어갈 수 있음
     + 이것보다 작을 경우 B와 C 양쪽에서 발생할 수 있음
     + 최악의 경우 $N^{3}$ 연산에서 $2N^{3} + N^{2}$ 메모리 워드 접근이 발생

   - 접근되는 원소가 캐시에 모두 들어가는 것을 보장하기 위해, 원래 코드를 부분행렬에 계산하는 코드를 변경
     + BLOCKSIZE X BLOCKSIZE 크기의 행렬에 대해 DGEMM을 반복해서 호출 : BLOCKSIZE는 블로킹 인수(Blocking Factor)라 함

   - DGEMM의 블록화 버전
<div align="center">
<img src="https://github.com/user-attachments/assets/8d24656e-ae96-4c02-a2e6-ea7f9697bcbe">
</div>

   - 함수 do_block은 DGEMM의 A, B, C의 각 부분행렬의 시작 위치를 나타내는 si, sj, sk 세 파라미터를 추가한 것
   - do_block의 두 내부 순환문은 B와 C 전체 크기 대신에 BLOCKSIZE 크기 단위로 계산
   - gcc 최적화 프로그램은 함수를 인라인화(Inlining)함으로써 함수 호출 오버헤드를 제거
     + 즉, 함수의 코드를 바로 삽입하여 기존의 파라미터 전달과 복귀 주소 관련 잡다한 명령어를 제거

   - 블로킹을 사용하여 세 배열에 접근
<div align="center">
<img src="https://github.com/user-attachments/assets/652bdf17-e11b-4656-b4c5-d7005fbedaf6">
</div>

   - 용량 실패만 고려하면 접근되는 메모리 워드 수는 모두 $2N^{3}/BLOCKSIZE + N^{2}$
   - 이 값은 BLOCKSIZE만큼의 성능 향상을 의미
     + A는 공간적 지역성에서 이점을 취하고, B는 시간적 지역성에서 이점을 취함으로, 블로킹은 공간과 시간 지역성 모두 이용
     + 컴퓨터와 행렬 크기에 따라 달라지기는 하지만 블로킹을 하면 약 2배에서 10배 이상까지 성능 개선

3. 블로킹의 목적은 캐시 실패를 줄이는 것이지만, 레지스터 할당을 돕는 데 사용될 수 있음
   - 블록이 레지스터에 들어갈 수 있을 만큼 블로킹 크기를 작게 하면 프로그램 적재와 저장 횟수를 줄일 수 있고 따라서 성능 향상도 가능

4. 다단계 캐시는 많은 복잡한 문제를 초래
   - 이들 중 하나는 여러 종류의 실패와 실패율이 존재한다는 점
   - 앞의 다단계 캐시 예제에서 1차 캐시 실패율과 전역 실패율(Global Miss Rate)을 보았음
     + 전역 실패율 : 다단계 캐시의 모든 계층에서 실패한 참조의 비율
   - 2차 캐시에는 또 다른 실패율이 있는데, 2차 캐시에서 발생한 실패의 수를 2차 캐시 접근 횟수로 나눈 것으로 2차 캐시의 지역 실패율(Local Miss Rate)라고 부름
     + 지역 실패율 : 다단계 캐시의 한 캐시 게층에서 실패한 참조의 비율로, 다단계 계층 구조에서 사용
   - 1차 캐시가 접근들, 특히 공간적 지역성과 시간적 지역성이 높은 접근들을 대부분 걸러내므로 2차 캐시 지역 실패율은 전역 실패율보다 훨씬 높음
   - 예를 들어, 앞 예제의 경우 2차 캐시 지역 실패율은 0.5% / 2% = 25%에 이름
   - 다행스럽게도 얼마나 자주 메인 메모리를 접근해야 하는지는 전역 실패율이 결정

5. 명령어를 순차적으로 수행하지 않을 수 있는 비순서 프로세서의 경우, 성능 계산이 훨씬 복잡
   - 실패를 처리하는 도중에도 명령어를 수행하므로, 명령어 실패율과 데이터 실패율 대신 명령어당 실패율을 사용해야함
<div align="center">
<img src="https://github.com/user-attachments/assets/bb530011-bace-4981-8a79-0ef470c2e5b1">
</div>

   - 중첩된 실패 손실을 계산하는 일반적인 방법은 없음
   - 따라서, 비순서 프로세서의 경우에는 불가피하게 프로세서와 메모리 계층 구조에 대한 시뮬레이션이 필요
   - 각각의 실패가 처리되는 동안 프로세서가 하는 일을 관찰해야만 프로세서가 데이터가 오기를 기다리면서 정지해있는지 아니면 다른 할 일을 찾아서 수행하는지 알 수 있음
   - 1차 캐시에서 실패하고 2차 캐시에서 적중하는 경우 프로세서가 대개 이 실패 손실을 감출 수 있지만, 1차 캐시와 2차 캐시에서 모두 실패하면 실패를 감출 수 있는 경우가 거의 없음

6. 알고리즘에 대한 성능 분석이 어려운 것은 같은 구조라도 구현에 따라 캐시 크기, 연관 정도, 블록 크기, 캐시 개수 등 메모리 계층 구조가 달라짐
   - 이러한 다양성에 대처하기 위해 최근 수치해석용 라이브러리들은 알고리즘을 파라미터화한 후, 실행 중 파라미터 공간을 탐색해 특정 컴퓨터에 가장 적합한 파라미터를 찾아내는데, 이러한 방법을 자동조정(Autotuning)
   
