-----
### 메모리 계층을 위한 공통 프레임워크
-----
1. 메모리 계층의 많은 부분들이 정량적으로 다를지라도 계층의 동작 방식을 결정하는 정책과 특징들은 정성적으로 유사
2. 메모리 계층의 정량적 특징이 다름을 보여주는 그림
<div align="center">
<img src="https://github.com/user-attachments/assets/dbf3fda6-a79b-43b6-8f2f-9a2906435c41">
</div>

3. 질문 1 : 블록을 어디에 넣을 수 있는가?
   - 메모리 계층구조의 상위 수준에 블록을 넣는 데 직접 사상, 집합 연관, 완전 연관 등과 같은 방식을 사용할 수 있음
   - 이 방법은 다 집합 연관 방식의 변형으로 생각할 수 있으며, 집합의 수와 집합 하나당 블록의 수가 다를 분
<div align="center">
<img src="https://github.com/user-attachments/assets/37e9e9a2-29b4-4857-a7fd-3a408f90b138">
</div>

   - 연관 정도를 증가시키는 것의 장점은 일반적으로 실패율을 감소시킨다는 것
   - 실패율의 향상은 같은 위치에 대한 충돌을 줄임으로써 가능
   - 직접 사상에서 8-way 집합 연관까지 연관 정도를 바꾸어 가면서 크기가 다른 캐시의 실패율을 보여줌
<div align="center">
<img src="https://github.com/user-attachments/assets/f6f6cc56-5862-4062-be02-16ed7b642054">
</div>

   - 가장 큰 이득은 직접 사상에서 2-way 집합 연관으로 바꿀 때 얻어지며, 이 때 실패율은 20% 내지 30% 줄어듬
   - 캐시가 커지면 연관 정도 증가에 의한 상대적인 성능 향상은 줄어듬
   - 큰 캐시는 실패율 자체가 낮으므로, 실패율을 향상시킬 수 있는 기회가 줄어들어 연관에 의한 실패율의 절대적 향상이 크게 위축됨
   - 연관 사상의 가장 잠재적인 단점은 비용 증가와 느린 접근시간

4. 질문 2 : 블록을 어떻게 찾을 것인가?
   - 블록 배치 방식이 블록이 들어갈 수 있는 장소의 수를 결정하므로, 블록을 찾는 방법은 블록 배치 방식에 따라 달라짐
   - 블록 배치 방식 요약
<div align="center">
<img src="https://github.com/user-attachments/assets/fda4156a-f27d-4071-bec7-c323fc1f92c0">
</div>

   - 모든 메모리 계층에서 직접 사상, 집합 연관, 완전 연관 중 하나를 선택하는 것은 연관 정도 구현 비용과 실패 비용에 의해 결정
   - 비용은 시간과 추가 하드웨어로 계산함
   - 칩 상의 L2 캐시는 적중시간이 크게 중요하지 않고, 표준 SRAM으로 구현하지 않아도 되므로 훨씬 더 높은 연관 정도를 사용할 수 있음
     + 완전 연관 방식은 작은 캐시가 아니면 사용할 수 없음
     + 작은 캐시에서는 비교기 비용이 너무 크지 않으면서 비교가 비용이 너무 크지 않으면서 절대적 실패율은 많이 향상되기 떄문에 써볼만 함
   - 가상 메모리 시스템에서는 메모리를 인덱스하기 위해 별도의 사상 테이블(페이지 테이블)을 사용
   - 인덱스 테이블을 사용하면 테이블을 저장할 공간이 필요할 뿐만 아니라 추가 메모리 접근이 필요
   - 그럼에도 불구하고 완전 연관 방식과 별도의 인덱스 테이블을 사용하는 이유
     + 실패 손실이 매우 크므로 완전 연관을 사용할 만 함
     + 완전 연관은 실패율을 줄이기 위해 설계된 정교한 교체 방식을 소프트웨어가 사용할 수 있도록 함
     + 완전한 사상 테이블은 추가 하드웨어나 검색 과정 없이 쉽게 인덱스할 수 있음

   - 그래서 가상 메모리 시스템은 항상 완전 연관 배치 방식을 사용
   - 집합 연관 배치는 캐시와 TLB에 종종 쓰이며, 접근은 인덱싱과 선택된 작은 집합 내 검색을 통해 이루어짐
   - 몇몇 시스템들은 접근시간과 간단함의 이점 때문에 직접 사상 캐시를 사용
     + 접근시간의 이점은 요청된 블록을 찾는 데 비교가 필요없기 때문에 생김
   - 이와 같은 설계에서의 선택은 구현의 세부사항에 따라 결정
     + 이 세부사항에는 캐시를 구현하는 데 사용한 기술이나 프로세서 사이클 시간을 결정하는 데 있어서 캐시 접근시간의 핵심적인 역할 등이 포함

5. 질문 3 : 캐시 실패가 발생하면 어느 블록을 교체할 것인가?
   - 연관 방식 캐시에서 실패가 발생하면 어느 블록을 교체할지 결정해야 함
     + 완전 연관 캐시에서는 모든 블록이 교체 후보가 됨
     + 집합 연관 캐시라면 선정된 집합 내 블록 중에서 선정해야 함
   - 물론 직접 사상 캐시에서는 후보가 단 하나이므로 교체가 간단
   - 집합 연관과 완전 연관 캐시의 주요 교체 전략
     + 무작위 교체 : 후보 블록이 무작위로 선정되며, 이 때 하드웨어의 지원을 받을 수 있음 (예를 들어 MIPS의 TLB 실패 시, 무작위 교체 방식을 사용)
     + LRU 교체 : 가장 오랫동안 사용되지 않은 블록을 선정

   - 실제로 낮은 연관 정도(일반적으로 2 ~ 4) 이상의 계층 구조에서 각 블록의 사용 정보를 추적하려면 비용이 많이 들기 때문에 LRU는 구현하기 어려움
   - 심지어 4-way 집합 연관에서도 LRU는 가끔 근사 방식으로 구현됨
     + 예를 들면 블록을 2개씩 묶어서 두 블럭 쌍 중 어느 것이 LRU인지 검사하고(1비트 필요), 다시 블록 쌍 내에서 어느 블록이 LRU인지를 검사(1비트 필요)하는 방식으로 구현 가능

   - 큰 연관 방식에서는 LRU 근사 방식을 이용하거나 무작위 교체 방식을 이용
   - 캐시에서는 교체 알고리즘이 하드웨어로 구현되므로 구현하기 쉬워야 함
   - 무작위 교체 방식은 하드웨어로 간단히 구현할 수 있음 : 2-way 집합 연관 캐시에서 무작위 교체는 LRU 교체보다 실패율이 약 1.1배 밖에 높지 않음
   - 캐시가 커지면 두 교체 방식의 실패율이 모두 떨어져서 절대적인 차이도 작아짐
   - 실제로 무작위 교체 방식이 하드웨어로 쉽게 구현할 수 있는 단순한 LRU 근사 방식보다 때로는 더 좋음
   - 가상 메모리에서는 실패 비용이 매우 커서 실패율의 작은 감소조차도 중요하기 때문에 항상 LRU 근사 방식이 사용됨
     + 운영체제가 가장 오래 전에 사용된 페이지를 쉽게 추적할 수 있도록 참조 비트 또는 이와 유사한 기능이 제공되는 경우가 많음
   - 실패는 비용이 많이 들고 상대적으로 드물게 발생하므로, 주로 소프트웨어를 사용하여 이 정보를 근사시키는 것이 받아들일만 함

6. 질문 4 : 쓰기는 어떻게 하는가?
   - 모든 메모리 계층의 중요한 특징은 쓰기를 어떻게 수행하는가에 있음
     + 즉시 쓰기 : 정보가 캐시 내 블록과 하위 계층(캐시의 경우 메인 메모리)의 블록 양쪽에 저장
     + 나중 쓰기 : 정보가 캐시 내 블록에만 저장되며, 수정된 블록은 교체될 때만 하위 계층으로 저장됨 (가상 메모리는 항상 이 방법 사용)

   - 이 두 가지 방법 모두 장점이 있지만, 나중 쓰기의 주요 장점
     + 프로세서는 각 워드를 메인 메모리가 아닌 캐시가 받아들일 수 있는 속도로 씀
     + 블록에 쓰기가 여러 번 일어나도 하위 계층에는 한 번만 쓰면 됨
     + 블록을 하위 게층에 쓸 때, 전체 블록을 한꺼번에 쓰기  때문에 높은 대역폭 전송을 효과적으로 이용할 수 있음

   - 즉시 쓰기의 장점
     + 실패가 발생해도 하위 계층에 블록을 쓸 필요가 없으므로, 실패 처리가 간단하고 비용이 적게 듬
     + 나중 쓰기보다 구현이 간단하지만, 즉시 쓰기가 실용성을 가지려면 쓰기 버퍼가 필요

   - 가상 메모리 시스템에서는 하위 계층에 쓸 때 지연시간이 크기 때문에 나중 쓰기 방식이 유용한 실용적 대안
   - 물리적으로 또 논리적으로 폭이 큰 메인 메모리를 사용하고 DRAM의 버스트 모드를 사용하더라도, 프로세서가 쓰기를 발생시키는 속도는 일반적으로 메모리 시스템이 쓰기를 처리한느 속도보다 빠르므로, 오늘날 최하위 계층 캐시들은 대개 나중 쓰기 방식을 사용하고 있음
  
